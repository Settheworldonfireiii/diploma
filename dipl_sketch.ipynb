{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing some Object Detection on a video\n",
    "reader = imageio.get_reader('funny_dog.mp4') # We open the video.\n",
    "fps = reader.get_meta_data()['fps'] # We get the fps frequence (frames per second).\n",
    "writer = imageio.get_writer('output.mp4', fps = fps) # We create an output video with this same fps frequence.\n",
    "for i, frame in enumerate(reader): # We iterate on the frames of the output video:\n",
    "    frame = detect(frame, net.eval(), transform) # We call our detect function (defined above) to detect the object on the frame.\n",
    "    writer.append_data(frame) # We add the next frame in the output video.\n",
    "    print(i) # We print the number of the processed frame.\n",
    "writer.close() # We close the process that handles the creation of the output video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import coco\n",
    "import utils\n",
    "import model as modellib\n",
    "import visualize\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Path to trained weights file\n",
    "# Download this file and place in the root of your \n",
    "# project (See README file for details)\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a random image from the images folder\n",
    "file_names = next(os.walk(IMAGE_DIR))[2]\n",
    "x = len(file_names)\n",
    "for k in range(x):\n",
    "    image = scipy.misc.imread(os.path.join(IMAGE_DIR, file_names[k]))\n",
    "\n",
    "    # Run detection\n",
    "    results = model.detect([image], verbose=1)\n",
    "\n",
    "    # Visualize results\n",
    "    r = results[0]\n",
    "    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            class_names, r['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import cv2\n",
    "\n",
    "reader = imageio.get_reader('0002-20170519-2.mp4') # We open the video.\n",
    "fps = reader.get_meta_data()['fps'] # We get the fps frequence (frames per second).\n",
    "writer = imageio.get_writer('output.mp4', fps = fps)\n",
    "\n",
    "for i, frame in enumerate(reader): # We iterate on the frames of the output video:\n",
    "    #frame = scipy.misc.imread(frame) # We call our detect function (defined above) to detect the object on the frame.\n",
    "    height, width = frame.shape[:2]\n",
    "    print(height, width, \"height, width\")\n",
    "    \n",
    "    results = model.detect([frame], verbose=1)\n",
    "    r = results[0]\n",
    "    print(r['rois'][0], \"rois 1\",len(r['scores']))\n",
    "    print(class_names[r['class_ids'][1]])\n",
    "    viz = visualize.display_instances(frame, r['rois'], r['masks'], r['class_ids'],class_names, r['scores'])\n",
    "    \n",
    "    #как писать на изображение, только это в торче, а тут тф\n",
    "    for j in range(len(r['scores'])): \n",
    "        if r['scores'][j] >= 0.6: # We take into account all the occurrences j of the class i that have a matching score larger than 0.6.\n",
    "            #pt = (detections[0, i, j, 1:] * scale).numpy() # We get the coordinates of the points at the upper left and the lower right of the detector rectangle.\n",
    "            #frame = frame[...,::-1]\n",
    "            frame=cv2.rectangle(frame, (int(r['scores'][0]), int(r['scores'][1])), (int(r['scores'][2]), int(r['scores'][3])), (255, 0, 0), 4) # We draw a rectangle around the detected object.\n",
    "            frame=cv2.putText(frame,class_names[r['class_ids'][j]], (int(r['scores'][0]), int(r['scores'][1])), cv2.FONT_HERSHEY_SIMPLEX, 4, (255, 255, 255), 2, cv2.LINE_AA) # We put the label of the class right above the rectangle.\n",
    "            if (i==0):\n",
    "                print(type(frame))\n",
    "                plt.imshow(frame)\n",
    "    \n",
    "    writer.append_data(frame) # We add the next frame in the output video.\n",
    "    \n",
    "    print(i) # We print the number of the processed frame.\n",
    "    if i==5:\n",
    "        break\n",
    "writer.close() # We close the process that handles the creation of the output video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://www.sroboto.com/2017/09/pass-video-into-tensorflow-object.html\n",
    "\n",
    "#https://github.com/smallcorgi/3D-Deepbox\n",
    "\n",
    "#https://github.com/MagaliDrumare/How-to-make-object-recognition-in-a-video-with-PyTorch-SSD/blob/master/object_detection_commented.py\n",
    "#https://dzone.com/articles/image-data-analysis-using-numpy-amp-opencv\n",
    "\n",
    "#https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html\n",
    "\n",
    "#http://www.cvlibs.net/datasets/kitti/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
